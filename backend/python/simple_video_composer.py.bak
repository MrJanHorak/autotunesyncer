#!/usr/bin/env python3
"""
SIMPLIFIED HIGH-PERFORMANCE VIDEO COMPOSER - CORRECTED VERSION

This is a streamlined version that removes the excessive complexity
and focuses on the core functionality that actually works well.

Key Performance Principles:
1. Simple direct processing (no over-engineered cache layers)
2. Correct drum handling with proper grid placement
3. Efficient memory management
4. Clear error handling

Based on working version from commit 0e2f4d9 but with bug fixes.
"""

import os
import sys
import logging
import math
import subprocess
import shutil
import time
from pathlib import Path
from concurrent.futures import ThreadPoolExecutor, as_completed

# Add current directory to path for imports
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from drum_utils import DRUM_NOTES, get_drum_name
from utils import normalize_instrument_name

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    force=True
)

class SimpleVideoComposer:
    """
    Simplified video composer focused on performance and reliability.
    
    Eliminates the complex optimization layers that were causing cache misses
    and performance degradation. Returns to proven direct processing approach
    with proper drum handling.
    """
    
    CHUNK_DURATION = 4.0
    FRAME_RATE = 30
    
    def __init__(self, processed_videos_dir, midi_data, output_path):
        self.processed_videos_dir = Path(processed_videos_dir)
        self.uploads_dir = self._find_uploads_dir()
        self.output_path = Path(output_path)
        self.midi_data = midi_data
        
        # Simple track organization
        self.regular_tracks = []
        self.drum_tracks = []
        self.grid_positions = {}
          # Performance settings
        self.max_workers = min(4, os.cpu_count())
        
        self._process_midi_data()
        self._setup_grid_positions()
        
        logging.info(f"‚úÖ SimpleVideoComposer initialized:")
        logging.info(f"   üìÅ Videos dir: {self.uploads_dir}")
        logging.info(f"   üéµ Regular tracks: {len(self.regular_tracks)}")
        logging.info(f"   ü•Å Drum tracks: {len(self.drum_tracks)}")

    def _find_uploads_dir(self):
        """Find the uploads directory containing video files"""
        # First try the processed_videos_dir itself (which is likely uploads)
        if any(self.processed_videos_dir.glob('*.mp4')):
            logging.info(f"Found uploads directory: {self.processed_videos_dir}")
            return self.processed_videos_dir
            
        uploads_dir = self.processed_videos_dir / "uploads"
        if uploads_dir.exists():
            logging.info(f"Found uploads directory: {uploads_dir}")
            return uploads_dir
        
        # Look for uploads directory in parent directories
        current = self.processed_videos_dir
        while current.parent != current:
            uploads_candidate = current / "uploads"
            if uploads_candidate.exists():
                logging.info(f"Found uploads directory: {uploads_candidate}")
                return uploads_candidate
            current = current.parent
        
        # Use processed_videos_dir itself if no uploads found
        logging.info(f"Using processed videos dir as uploads: {self.processed_videos_dir}")
        return self.processed_videos_dir

    def _process_midi_data(self):
        """Process MIDI data into simple track structure"""
        tracks = self.midi_data.get('tracks', [])
        
        for idx, track in enumerate(tracks):
            normalized_track = self._normalize_track(track, idx)
            
            if self._is_drum_track(track):
                self.drum_tracks.append(normalized_track)
                logging.info(f"Drum track {idx}: {track.get('instrument', {}).get('name', 'Unknown')}")
            else:
                self.regular_tracks.append(normalized_track)
                logging.info(f"Regular track {idx}: {track.get('instrument', {}).get('name', 'Unknown')}")

    def _normalize_track(self, track, idx):
        """Convert track to standard format"""
        return {
            'id': track.get('id', str(idx)),
            'index': idx,            'instrument': track.get('instrument', {'name': 'Unknown'}),
            'notes': track.get('notes', []),
            'channel': track.get('channel', 0),
            'isDrum': self._is_drum_track(track)
        }

    def _is_drum_track(self, track):
        """Accurate drum track detection"""
        # Check channel 9 (standard drum channel) - this is the primary indicator
        if track.get('channel') == 9:
            return True
        
        # Check instrument name for explicit drum indicators
        instrument_name = track.get('instrument', {}).get('name', '').lower()
        drum_keywords = ['drum', 'percussion', 'kit', 'cymbal', 'snare', 'kick', 'hihat', 'hi-hat']
        if any(keyword in instrument_name for keyword in drum_keywords):
            return True
        
        # For non-channel-9 tracks, be very conservative
        # Only classify as drum if the instrument name explicitly indicates drums
        return False

    def _setup_grid_positions(self):
        """Setup grid positions from MIDI data"""
        grid_arrangement = self.midi_data.get('gridArrangement', {})
        
        if not grid_arrangement:
            # Create default grid arrangement
            total_tracks = len(self.regular_tracks) + len(self.drum_tracks)
            cols = min(4, total_tracks)
            
            idx = 0
            for track in self.regular_tracks + self.drum_tracks:
                self.grid_positions[track['id']] = {
                    'row': idx // cols,
                    'column': idx % cols
                }
                idx += 1
        else:
            # Use provided grid arrangement
            for track_id, pos_data in grid_arrangement.items():
                if isinstance(pos_data, dict) and 'row' in pos_data and 'column' in pos_data:
                    self.grid_positions[track_id] = {
                        'row': int(pos_data['row']),
                        'column': int(pos_data['column'])
                    }
        
        logging.info(f"Grid positions set for {len(self.grid_positions)} tracks")

    def create_composition(self):
        """
        Create video composition using simplified, proven approach.
        
        This method eliminates the complex optimization layers and focuses
        on direct, efficient processing that actually works.
        """
        try:
            logging.info("üé¨ Starting SIMPLIFIED video composition...")
            start_time = time.time()
            
            # Calculate composition parameters
            total_duration = self._calculate_total_duration()
            total_chunks = max(1, math.ceil(total_duration / self.CHUNK_DURATION))
            
            logging.info(f"Composition: {total_duration:.2f}s, {total_chunks} chunks")
            
            # Create chunks directory
            chunks_dir = self.processed_videos_dir / "simple_chunks"
            chunks_dir.mkdir(exist_ok=True)
            
            # Process chunks in parallel for performance
            chunk_paths = []
            with ThreadPoolExecutor(max_workers=self.max_workers) as executor:
                chunk_futures = {}
                
                for chunk_idx in range(total_chunks):
                    chunk_start = chunk_idx * self.CHUNK_DURATION
                    chunk_end = min(chunk_start + self.CHUNK_DURATION, total_duration)
                    
                    future = executor.submit(
                        self._create_chunk, 
                        chunk_idx, chunk_start, chunk_end, chunks_dir
                    )
                    chunk_futures[future] = chunk_idx
                
                # Collect results
                for future in as_completed(chunk_futures):
                    chunk_idx = chunk_futures[future]
                    try:
                        chunk_path = future.result()
                        if chunk_path:
                            chunk_paths.append((chunk_idx, chunk_path))
                            logging.info(f"‚úÖ Chunk {chunk_idx + 1}/{total_chunks} completed")
                        else:
                            logging.warning(f"‚ö†Ô∏è  Chunk {chunk_idx + 1} failed")
                    except Exception as e:
                        logging.error(f"‚ùå Chunk {chunk_idx + 1} error: {e}")
            
            # Sort chunks by index and concatenate
            chunk_paths.sort(key=lambda x: x[0])
            sorted_paths = [path for _, path in chunk_paths]
            
            if not sorted_paths:
                raise Exception("No chunks were created successfully")
            
            # Concatenate chunks into final video
            final_path = self._concatenate_chunks(sorted_paths)
            
            total_time = time.time() - start_time
            if final_path and os.path.exists(final_path):
                file_size = os.path.getsize(final_path)
                logging.info(f"üéâ COMPOSITION SUCCESSFUL!")
                logging.info(f"   üìÅ Output: {final_path}")
                logging.info(f"   üìè Size: {file_size:,} bytes")
                logging.info(f"   ‚è±Ô∏è  Total time: {total_time:.2f}s")
                return str(final_path)
            else:
                logging.error("‚ùå Final concatenation failed")
                return None
                
        except Exception as e:
            logging.error(f"‚ùå Composition error: {e}")
            import traceback
            logging.error(f"Full traceback: {traceback.format_exc()}")
            return None

    def _calculate_total_duration(self):
        """Calculate total composition duration"""
        max_duration = 0
        
        for track in self.regular_tracks + self.drum_tracks:
            for note in track.get('notes', []):
                note_start = float(note.get('time', 0))
                note_duration = float(note.get('duration', 1))
                note_end = note_start + note_duration
                max_duration = max(max_duration, note_end)
        
        return max(max_duration, 1.0)  # At least 1 second

    def _create_chunk(self, chunk_idx, start_time, end_time, chunks_dir):
        """Create a single chunk with proper drum handling"""
        try:
            chunk_duration = end_time - start_time
            chunk_path = chunks_dir / f"chunk_{chunk_idx}.mp4"
            
            # Find active tracks in this time range
            active_tracks = self._find_active_tracks(start_time, end_time)
            
            if not active_tracks:
                return self._create_silent_chunk(chunk_path, chunk_duration)
            
            # Process each active track to get video segments
            track_videos = []
            
            for track in active_tracks:
                if track['isDrum']:
                    drum_videos = self._process_drum_track_chunk(track, start_time, end_time)
                    track_videos.extend(drum_videos)
                else:
                    regular_video = self._process_regular_track_chunk(track, start_time, end_time)
                    if regular_video:
                        track_videos.append(regular_video)
            
            if not track_videos:
                return self._create_silent_chunk(chunk_path, chunk_duration)
            
            # Combine all track videos into grid layout
            return self._create_grid_composition(track_videos, chunk_path, chunk_duration)
            
        except Exception as e:
            logging.error(f"Error creating chunk {chunk_idx}: {e}")
            return None

    def _find_active_tracks(self, start_time, end_time):
        """Find tracks that have notes active in the time range"""
        active_tracks = []
        
        for track in self.regular_tracks + self.drum_tracks:
            has_active_notes = False
            
            for note in track.get('notes', []):
                note_start = float(note.get('time', 0))
                note_end = note_start + float(note.get('duration', 1))
                
                if note_start < end_time and note_end > start_time:
                    has_active_notes = True
                    break
            
            if has_active_notes:
                active_tracks.append(track)
        
        return active_tracks

    def _process_drum_track_chunk(self, drum_track, start_time, end_time):
        """
        Process drum track with CORRECT drum handling.
        
        This fixes the main drum processing issue by:
        1. Correctly mapping MIDI notes to specific drum sounds
        2. Finding the right drum video files 
        3. Placing them in correct grid positions based on drum type
        """
        drum_videos = []
        
        # Group notes by drum type (MIDI note number)
        drum_notes_by_type = {}
        
        for note in drum_track.get('notes', []):
            note_start = float(note.get('time', 0))
            note_end = note_start + float(note.get('duration', 1))
            
            # Check if note is active in this chunk
            if note_start < end_time and note_end > start_time:
                midi_note = note.get('midi')
                drum_name = get_drum_name(midi_note)
                
                if drum_name != 'Unknown':
                    if drum_name not in drum_notes_by_type:
                        drum_notes_by_type[drum_name] = []
                    drum_notes_by_type[drum_name].append(note)
        
        # Process each drum type separately
        for drum_name, notes in drum_notes_by_type.items():
            drum_video_path = self._find_drum_video_file(drum_name)
            
            if drum_video_path:
                # Create video segment for this drum type
                drum_video_info = {
                    'path': drum_video_path,
                    'track_id': f"drum_{drum_name.lower().replace(' ', '_')}",
                    'notes': notes,
                    'start_time': start_time,
                    'drum_name': drum_name
                }
                drum_videos.append(drum_video_info)
                logging.info(f"‚úÖ Drum: {drum_name} ‚Üí {os.path.basename(drum_video_path)}")
            else:
                logging.warning(f"‚ùå No video file found for drum: {drum_name}")
        
        return drum_videos

    def _find_drum_video_file(self, drum_name):
        """Find the video file for a specific drum sound with enhanced matching"""
        # Normalize drum name for file matching
        normalized_drum = f"drum_{drum_name.lower().replace(' ', '_')}"
        
        # Look for files in uploads directory
        for video_file in self.uploads_dir.glob('*.mp4'):
            if normalized_drum in video_file.name.lower():
                return str(video_file)
        
        # Also check for processed files
        for video_file in self.uploads_dir.glob('processed_*.mp4'):
            if normalized_drum in video_file.name.lower():
                return str(video_file)
        
        # Try partial matching for drum variations
        # Common drum name mappings for files we have
        drum_variations = {
            'snare_drum': ['snare_cross_stick', 'snare'],
            'kick_drum': ['bass_drum', 'kick'],
            'hi-hat_closed': ['hihat_closed', 'hi_hat_closed'],
            'crash_cymbal': ['crash'],
        }
        
        normalized_base = drum_name.lower().replace(' ', '_')
        for video_file in self.uploads_dir.glob('processed_*.mp4'):
            file_name_lower = video_file.name.lower()
            
            # Check if any variation matches
            variations = drum_variations.get(normalized_base, [normalized_base])
            for variation in variations:
                if f"drum_{variation}" in file_name_lower:
                    logging.info(f"Matched drum '{drum_name}' to '{video_file.name}' via variation '{variation}'")
                    return str(video_file)
        
        logging.warning(f"No video file found for drum: {drum_name} (looking for {normalized_drum})")
        return None

    def _process_regular_track_chunk(self, track, start_time, end_time):
        """Process regular (non-drum) track chunk"""
        # Find the video file for this instrument
        instrument_name = track['instrument']['name']
        normalized_name = normalize_instrument_name(instrument_name)
        
        video_file = self._find_instrument_video_file(normalized_name)
        if not video_file:
            logging.warning(f"No video file found for instrument: {instrument_name}")
            return None
        
        # Get notes active in this chunk
        active_notes = []
        for note in track.get('notes', []):
            note_start = float(note.get('time', 0))
            note_end = note_start + float(note.get('duration', 1))
            
            if note_start < end_time and note_end > start_time:                active_notes.append(note)
        
        if not active_notes:
            return None
            
        return {
            'path': video_file,
            'track_id': track['id'],
            'notes': active_notes,
            'start_time': start_time,
            'instrument_name': instrument_name
        }
        
    def _find_instrument_video_file(self, instrument_name):
        """Find the video file for an instrument with enhanced matching"""
        # Normalize instrument name for better matching
        normalized_name = instrument_name.lower().replace(' ', '_').replace('(', '').replace(')', '').replace('+', '').replace('-', '_')
        
        # Look for files matching the instrument name
        for video_file in self.uploads_dir.glob('*.mp4'):
            file_name_lower = video_file.name.lower()
            # Try direct match first
            if instrument_name.lower() in file_name_lower:
                return str(video_file)
            # Try normalized match
            if normalized_name in file_name_lower:
                return str(video_file)
            
        # Also check for processed files
        for video_file in self.uploads_dir.glob('processed_*.mp4'):
            file_name_lower = video_file.name.lower()
            # Try direct match first
            if instrument_name.lower() in file_name_lower:
                return str(video_file)
            # Try normalized match
            if normalized_name in file_name_lower:
                return str(video_file)
        
        # Try partial matching for complex names
        name_parts = instrument_name.lower().split()
        for video_file in self.uploads_dir.glob('processed_*.mp4'):
            file_name_lower = video_file.name.lower()
            if any(part in file_name_lower for part in name_parts if len(part) > 2):
                logging.info(f"Matched '{instrument_name}' to '{video_file.name}' via partial match")
                return str(video_file)
        
        return None
        
    def _create_grid_composition(self, track_videos, output_path, duration):
        """Create grid-based composition from track videos"""
        try:
            if not track_videos:
                return self._create_silent_chunk(output_path, duration)
            
            logging.info(f"üé¨ Creating grid with {len(track_videos)} videos")
            
            # IMPORTANT: Always create a grid layout instead of using just one video directly
            # This ensures even single videos are properly placed in the grid
            cmd = ['ffmpeg', '-y']
            
            # Add all input videos
            for video in track_videos:
                cmd.extend(['-i', video['path']])
                logging.info(f"Adding video to grid: {os.path.basename(video['path'])}")
            
            # Calculate grid dimensions
            video_count = len(track_videos)
            
            # Always use a grid layout with at least 2x2 cells to ensure proper display
            if video_count == 1:
                # Single video still goes in a quadrant
                cols, rows = 2, 2
                width, height = 960, 540
            elif video_count == 2:
                cols, rows = 2, 1
                width, height = 960, 540  # Split screen
            elif video_count <= 4:
                cols, rows = 2, 2
                width, height = 960, 540  # Quad
            else:
                cols = min(4, math.ceil(math.sqrt(video_count)))
                rows = math.ceil(video_count / cols)
                width, height = 1920 // cols, 1080 // rows
            
            # Build filter complex for grid layout
            video_filters = []
            audio_inputs = []
            
            # Scale and pad each video to ensure consistent size
            for i in range(video_count):
                # Force scale with padding to maintain aspect ratio
                video_filters.append(f'[{i}:v]scale={width}:{height}:force_original_aspect_ratio=decrease,pad={width}:{height}:(ow-iw)/2:(oh-ih)/2:black[v{i}]')
                audio_inputs.append(f'[{i}:a]')
            
            # Create grid overlay
            if video_count == 1:
                # Single video gets placed in the top-left of a 2x2 grid
                overlay_filter = '[v0]pad=1920:1080:0:0[v]'
            elif video_count == 2:
                overlay_filter = '[v0][v1]hstack=inputs=2[v]'
            elif video_count == 3:
                # 2x2 grid with 3 videos
                overlay_filter = '[v0][v1]hstack=inputs=2[top];[v2]pad=1920:540:0:0[bottom];[top][bottom]vstack=inputs=2[v]'
            elif video_count == 4:
                # 2x2 grid
                overlay_filter = '[v0][v1]hstack=inputs=2[top];[v2][v3]hstack=inputs=2[bottom];[top][bottom]vstack=inputs=2[v]'
            else:
                # More complex grid - use overlay positioning with explicit coordinates
                overlay_chain = f'[v0]pad={cols*width}:{rows*height}:0:0[base];[base]'
                for i in range(1, video_count):
                    row = i // cols
                    col = i % cols
                    x = col * width
                    y = row * height
                    
                    if i == video_count - 1:
                        overlay_chain += f'[v{i}]overlay={x}:{y}[v]'
                    else:
                        overlay_chain += f'[v{i}]overlay={x}:{y}[tmp{i}];[tmp{i}]'
                overlay_filter = overlay_chain
            
            # Mix audio - use amerge+pan for better control instead of amix
            if len(audio_inputs) > 1:
                audio_filter = f'{"".join(audio_inputs)}amerge=inputs={len(audio_inputs)},pan=stereo|c0<c0+c2+c4|c1<c1+c3+c5[a]'
            else:
                audio_filter = '[0:a]anull[a]'
            
            # Debug the filter graph being used
            filter_complex = ';'.join(video_filters + [overlay_filter, audio_filter])
            logging.info(f"FFmpeg filter graph: {filter_complex}")
            
            cmd.extend([
                '-filter_complex', filter_complex,
                '-map', '[v]',
                '-map', '[a]',
                '-t', str(duration),
                '-c:v', 'libx264', '-preset', 'fast', '-crf', '23',
                '-c:a', 'aac', '-b:a', '192k',                str(output_path)
            ])
            
            logging.info(f"üìê Grid layout: {cols}x{rows}, cell size: {width}x{height}, videos: {video_count}")
            
            # Execute FFmpeg command
            result = subprocess.run(cmd, capture_output=True, text=True, encoding='utf-8', errors='replace')
            if result.returncode == 0:
                # Verify the output file exists and has reasonable size
                if os.path.exists(output_path) and os.path.getsize(output_path) > 10000:
                    logging.info(f"‚úÖ Grid composition created: {os.path.basename(output_path)}")
                    logging.info(f"   üìè Output size: {os.path.getsize(output_path):,} bytes")
                    return str(output_path)
                else:
                    logging.error(f"Grid composition created but file is empty or too small: {os.path.getsize(output_path)} bytes")
                    return None
            else:
                logging.error(f"FFmpeg error: {result.stderr}")
                logging.error(f"Command: {' '.join(cmd)}")
                return None
                
        except Exception as e:
            logging.error(f"Error creating grid composition: {e}")
            import traceback
            logging.error(f"Traceback: {traceback.format_exc()}")
            return None

    def _create_silent_chunk(self, output_path, duration):
        """Create a silent video chunk"""
        try:
            cmd = [
                'ffmpeg', '-y',
                '-f', 'lavfi',
                '-i', 'color=black:size=1920x1080:duration=' + str(duration),
                '-f', 'lavfi',
                '-i', 'anullsrc=channel_layout=stereo:sample_rate=44100',
                '-c:v', 'libx264', '-preset', 'fast', '-crf', '23',
                '-c:a', 'aac', '-shortest',
                str(output_path)
            ]
            
            result = subprocess.run(cmd, capture_output=True, text=True, encoding='utf-8', errors='replace')            if result.returncode == 0:
                return str(output_path)
            else:
                logging.error(f"Failed to create silent chunk: {result.stderr}")
                return None
                
        except Exception as e:
            logging.error(f"Error creating silent chunk: {e}")
            return None
            
    def _concatenate_chunks(self, chunk_paths):
        """Concatenate chunks into final video while preserving grid layouts"""
        try:
            # Create concat file list
            concat_file = self.processed_videos_dir / "concat_list.txt"
            
            with open(concat_file, 'w', encoding='utf-8') as f:
                for chunk_path in chunk_paths:
                    f.write(f"file '{chunk_path}'\n")
            
            # Concatenate using FFmpeg - CRITICAL: Do NOT use -c copy as it loses grid layout
            final_path = self.output_path
            cmd = [
                'ffmpeg', '-y',
                '-f', 'concat',
                '-safe', '0',
                '-i', str(concat_file),
                # FIXED: Re-encoding with higher quality settings to preserve grid layout
                # Using a higher bitrate to ensure visual fidelity of grid layouts
                '-c:v', 'libx264', '-preset', 'medium', '-crf', '20',
                '-c:a', 'aac', '-b:a', '256k',
                # Ensure proper format settings for grid preservation
                '-pix_fmt', 'yuv420p', 
                # Force same output dimensions as input to preserve grid layout
                '-vsync', '2',
                str(final_path)
            ]
            
            logging.info(f"üîÑ Concatenating {len(chunk_paths)} chunks with FIXED grid-preserving settings...")
            logging.info(f"   ‚öôÔ∏è Using full re-encode to maintain grid layouts")
            
            result = subprocess.run(cmd, capture_output=True, text=True, encoding='utf-8', errors='replace')
            if result.returncode == 0:
                # Cleanup
                os.unlink(concat_file)
                for chunk_path in chunk_paths:
                    try:
                        os.unlink(chunk_path)
                    except:
                        pass
                
                # Verify the output file size to ensure it's not just a single track
                output_size = os.path.getsize(final_path)
                logging.info(f"‚úÖ Successfully concatenated {len(chunk_paths)} chunks with grid layout preservation")
                logging.info(f"   üìè Final output size: {output_size:,} bytes")
                
                return str(final_path)
            else:
                logging.error(f"‚ùå FFmpeg concatenation error: {result.stderr}")
                return None
                
        except Exception as e:
            logging.error(f"‚ùå Error concatenating chunks: {e}")
            import traceback
            logging.error(f"Full traceback: {traceback.format_exc()}")
            return None
